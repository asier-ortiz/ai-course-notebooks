{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Importación de librerías",
   "id": "45b7e8004ac10693"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.applications import VGG16, ResNet50\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "# TODO Random Seed"
   ],
   "id": "e4f499804fc267d8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Descarga y extracción del dataset",
   "id": "3580995d92c8a5e3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Definir rutas\n",
    "data_dir = \"data\"\n",
    "base_dir = os.path.join(data_dir, \"PetImages\")\n",
    "zip_path = os.path.join(data_dir, \"kagglecatsanddogs_5340.zip\")\n",
    "extract_path = os.path.join(data_dir, \"kagglecatsanddogs\")\n",
    "url = \"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip\"\n",
    "\n",
    "# Crear la carpeta 'data/' si no existe\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "# Si PetImages no existe, descargar el dataset\n",
    "if not os.path.exists(base_dir):\n",
    "    print(\"Dataset no encontrado. Descargando...\")\n",
    "\n",
    "    # Descargar el dataset\n",
    "    urllib.request.urlretrieve(url, zip_path)\n",
    "    print(f\"Dataset descargado en {zip_path}\")\n",
    "\n",
    "    # Extraer el dataset\n",
    "    print(\"Extrayendo dataset...\")\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(data_dir)\n",
    "    print(\"Extracción completada.\")\n",
    "\n",
    "    # Mover la carpeta PetImages a data/ si aún no está allí\n",
    "    extracted_petimages = os.path.join(extract_path, \"PetImages\")\n",
    "    if os.path.exists(extracted_petimages):\n",
    "        shutil.move(extracted_petimages, base_dir)\n",
    "        print(\"Carpeta PetImages movida correctamente.\")\n",
    "\n",
    "    # Eliminar el archivo ZIP\n",
    "    os.remove(zip_path)\n",
    "    print(\"Archivo ZIP eliminado.\")\n",
    "\n",
    "    # Eliminar archivos innecesarios\n",
    "    for file_name in [\"CDLA-Permissive-2.0.pdf\", \"readme[1].txt\"]:\n",
    "        file_path = os.path.join(data_dir, file_name)\n",
    "        if os.path.exists(file_path):\n",
    "            os.remove(file_path)\n",
    "            print(f\"Eliminado: {file_name}\")\n",
    "\n",
    "    print(f\"Dataset listo en {base_dir}\")\n",
    "\n",
    "else:\n",
    "    print(\"El dataset ya existe. No es necesario descargarlo.\")"
   ],
   "id": "9c70b6d9800bf3ab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Organización de datos",
   "id": "e8a026ac35d16932"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Definir rutas de train y test\n",
    "train_dir = os.path.join(base_dir, \"train\")\n",
    "test_dir = os.path.join(base_dir, \"test\")\n",
    "\n",
    "# Crear directorios de train/test y sus subcarpetas si no existen\n",
    "for dir_path in [train_dir, test_dir]:\n",
    "    os.makedirs(os.path.join(dir_path, \"Cat\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(dir_path, \"Dog\"), exist_ok=True)\n",
    "\n",
    "\n",
    "def split_data(class_name, num_train, num_test):\n",
    "    \"\"\"\n",
    "    Divide imágenes en train y test, asegurando que estén balanceadas.\n",
    "    Si hay menos imágenes de las necesarias, usa todas las disponibles.\n",
    "    \"\"\"\n",
    "    src_dir = os.path.join(base_dir, class_name)\n",
    "    train_dest = os.path.join(train_dir, class_name)\n",
    "    test_dest = os.path.join(test_dir, class_name)\n",
    "\n",
    "    # Verificar si la carpeta de origen existe\n",
    "    if not os.path.exists(src_dir):\n",
    "        print(f\"Advertencia: No se encontró la carpeta {src_dir}, omitiendo esta clase.\")\n",
    "        return\n",
    "\n",
    "    # Obtener todas las imágenes disponibles\n",
    "    images = [img for img in os.listdir(src_dir) if img.endswith(\".jpg\")]\n",
    "    random.shuffle(images)\n",
    "\n",
    "    # Tomar las imágenes necesarias, si hay menos de las requeridas, usar todas\n",
    "    train_images = images[:min(num_train, len(images))]\n",
    "    test_images = images[min(num_train, len(images)):min(num_train + num_test, len(images))]\n",
    "\n",
    "    # Copiar imágenes al dataset\n",
    "    for img in train_images:\n",
    "        shutil.copy(os.path.join(src_dir, img), os.path.join(train_dest, img))\n",
    "    for img in test_images:\n",
    "        shutil.copy(os.path.join(src_dir, img), os.path.join(test_dest, img))\n",
    "\n",
    "    print(f\"{class_name} dividido en Train: {len(train_images)}, Test: {len(test_images)}\")\n",
    "\n",
    "\n",
    "# Configurar cantidad de imágenes para el segundo escenario\n",
    "num_train = 5000\n",
    "num_test = 1000\n",
    "\n",
    "# Aplicar división asegurando que cada clase tenga las imágenes necesarias\n",
    "split_data(\"Cat\", num_train, num_test)\n",
    "split_data(\"Dog\", num_train, num_test)\n",
    "\n",
    "print(\"Datos organizados en train y test correctamente.\")"
   ],
   "id": "f14ae806082cd62e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Carga de datos",
   "id": "5dde4eb1b7f7b490"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "IMG_SIZE = 128\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Cargar datasets de entrenamiento y test\n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode=\"binary\"\n",
    ")\n",
    "\n",
    "test_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    seed=42,\n",
    "    shuffle=False,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode=\"binary\"\n",
    ")\n",
    "\n",
    "# Normalización de imágenes\n",
    "normalization_layer = tf.keras.layers.Rescaling(1. / 255)\n",
    "train_dataset = train_dataset.map(lambda x, y: (normalization_layer(x), y)).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "test_dataset = test_dataset.map(lambda x, y: (normalization_layer(x), y)).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "print(\"Datos cargados y normalizados correctamente.\")"
   ],
   "id": "d06979e9f6b21eab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Definición de modelos",
   "id": "3e337d3fa74bce96"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# MODELO 1: CNN SIMPLE\n",
    "def create_simple_cnn():\n",
    "    model = Sequential([\n",
    "        tf.keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
    "        Conv2D(32, (3, 3), activation=\"relu\"),\n",
    "        MaxPooling2D(2, 2),\n",
    "        Flatten(),\n",
    "        Dense(128, activation=\"relu\"),\n",
    "        Dense(1, activation=\"sigmoid\")  # Salida binaria (perro o gato)\n",
    "    ])\n",
    "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model"
   ],
   "id": "4cafadcccdb49d1f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# MODELO 2: CNN PROFUNDA\n",
    "def create_deep_cnn():\n",
    "    model = Sequential([\n",
    "\n",
    "        # Capa de entrada: Define el tamaño de las imágenes de entrada (128x128 con 3 canales RGB)\n",
    "        tf.keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
    "\n",
    "        # Primera capa convolucional:\n",
    "        # - 32 filtros de tamaño 3x3\n",
    "        # - Activación ReLU para introducir no linealidad\n",
    "        Conv2D(32, (3, 3), activation=\"relu\"),\n",
    "\n",
    "        # Primera capa de MaxPooling:\n",
    "        # - Reduce la dimensionalidad (divide la imagen por 2 en cada dimensión)\n",
    "        MaxPooling2D(2, 2),\n",
    "\n",
    "        # Segunda capa convolucional:\n",
    "        # - 64 filtros de tamaño 3x3\n",
    "        # - Detecta patrones más complejos que la primera capa\n",
    "        Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "\n",
    "        # Segunda capa de MaxPooling:\n",
    "        MaxPooling2D(2, 2),\n",
    "\n",
    "        # Tercera capa convolucional:\n",
    "        # - 128 filtros de tamaño 3x3\n",
    "        # - Aprende características aún más abstractas de la imagen\n",
    "        Conv2D(128, (3, 3), activation=\"relu\"),\n",
    "\n",
    "        # Tercera capa de MaxPooling:\n",
    "        MaxPooling2D(2, 2),\n",
    "\n",
    "        # Capa Flatten:\n",
    "        # - Convierte la salida 3D de las capas convolucionales en una sola dimensión\n",
    "        # - Esto es necesario para conectar con las capas densas (fully connected)\n",
    "        Flatten(),\n",
    "\n",
    "        # Capa densa (fully connected):\n",
    "        # - 256 neuronas con activación ReLU\n",
    "        # - Aprende combinaciones de características extraídas por las capas convolucionales\n",
    "        Dense(256, activation=\"relu\"),\n",
    "\n",
    "        # Capa de Dropout:\n",
    "        # - Ayuda a reducir el overfitting desactivando aleatoriamente el 50% de las neuronas\n",
    "        Dropout(0.5),\n",
    "\n",
    "        # Capa de salida:\n",
    "        # - 1 neurona con activación sigmoide (para clasificación binaria)\n",
    "        Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "\n",
    "    # Compilación del modelo:\n",
    "    # - Optimizador Adam: Ajusta los pesos de la red de manera eficiente\n",
    "    # - Función de pérdida Binary Crossentropy: Para problemas de clasificación binaria\n",
    "    # - Métrica de precisión para evaluar el rendimiento\n",
    "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    return model"
   ],
   "id": "ded8e80002628f4f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# MODELO 3: VGG16\n",
    "def create_vgg16():\n",
    "    base_model = VGG16(weights=\"imagenet\", include_top=False)\n",
    "    base_model.trainable = False  # Congelar pesos\n",
    "\n",
    "    model = Sequential([\n",
    "        tf.keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
    "        base_model,\n",
    "        Flatten(),\n",
    "        Dense(128, activation=\"relu\"),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model"
   ],
   "id": "6f6f22107e57b54",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# MODELO 4: ResNet50\n",
    "def create_resnet50():\n",
    "    base_model = ResNet50(weights=\"imagenet\", include_top=False)\n",
    "    base_model.trainable = False  # Congelar pesos\n",
    "\n",
    "    model = Sequential([\n",
    "        tf.keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
    "        base_model,\n",
    "        Flatten(),\n",
    "        Dense(128, activation=\"relu\"),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model"
   ],
   "id": "df5ee98d22dc32c8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Entranamiento de modelos",
   "id": "f23e389186a79218"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "EPOCHS = 5\n",
    "history_dict = {}\n",
    "evaluation_metrics = {}"
   ],
   "id": "e121543fe94c10ca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Red Neuronal Convolucional (CNN) Simple",
   "id": "e56b40b098a05796"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# CNN Simple\n",
    "\n",
    "cnn_simple = create_simple_cnn()\n",
    "\n",
    "print(\"\\nEntrenando CNN Simple...\\n\")\n",
    "history_cnn_simple = cnn_simple.fit(train_dataset, epochs=EPOCHS, validation_data=test_dataset, verbose=-1)\n",
    "\n",
    "# Guardar historial\n",
    "history_dict[\"CNN Simple\"] = history_cnn_simple\n",
    "\n",
    "# Evaluar modelo\n",
    "loss, acc = cnn_simple.evaluate(test_dataset)\n",
    "evaluation_metrics[\"CNN Simple\"] = acc\n",
    "\n",
    "print(f\"CNN Simple entrenado correctamente - Loss: {loss:.4f}, Accuracy: {acc:.4f}\")"
   ],
   "id": "143824b67e02d718",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Red Neuronal Convolucional (CNN) Profunda",
   "id": "da8d3dece28f8356"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# CNN Profunda\n",
    "\n",
    "cnn_deep = create_deep_cnn()\n",
    "\n",
    "print(\"\\nEntrenando CNN Profunda...\\n\")\n",
    "history_cnn_deep = cnn_deep.fit(train_dataset, epochs=EPOCHS, validation_data=test_dataset, verbose=-1)\n",
    "\n",
    "# Guardar historial\n",
    "history_dict[\"CNN Profunda\"] = history_cnn_deep\n",
    "\n",
    "# Evaluar modelo\n",
    "loss, acc = cnn_deep.evaluate(test_dataset)\n",
    "evaluation_metrics[\"CNN Profunda\"] = acc\n",
    "\n",
    "print(f\"CNN Profunda entrenado correctamente - Loss: {loss:.4f}, Accuracy: {acc:.4f}\")"
   ],
   "id": "bcc0ab8b40181254",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### VGG16 (CNN preentrenada con Transfer Learning)",
   "id": "b7adde31e817346f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# VGG16\n",
    "\n",
    "vgg16_model = create_vgg16()\n",
    "\n",
    "print(\"\\nEntrenando VGG16...\\n\")\n",
    "history_vgg16 = vgg16_model.fit(train_dataset, epochs=EPOCHS, validation_data=test_dataset, verbose=-1)\n",
    "\n",
    "# Guardar historial\n",
    "history_dict[\"VGG16\"] = history_vgg16\n",
    "\n",
    "# Evaluar modelo\n",
    "loss, acc = vgg16_model.evaluate(test_dataset)\n",
    "evaluation_metrics[\"VGG16\"] = acc\n",
    "\n",
    "print(f\"VGG16 entrenado correctamente - Loss: {loss:.4f}, Accuracy: {acc:.4f}\")"
   ],
   "id": "f73e9d32c80fcb5e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### ResNet50 (CNN preentrenada con Transfer Learning)",
   "id": "f88dc203d49b64f7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ResNet50\n",
    "\n",
    "resnet50_model = create_resnet50()\n",
    "\n",
    "print(\"\\nEntrenando ResNet50...\\n\")\n",
    "history_resnet50 = resnet50_model.fit(train_dataset, epochs=EPOCHS, validation_data=test_dataset, verbose=-1)\n",
    "\n",
    "# Guardar historial\n",
    "history_dict[\"ResNet50\"] = history_resnet50\n",
    "\n",
    "# Evaluar modelo\n",
    "loss, acc = resnet50_model.evaluate(test_dataset)\n",
    "evaluation_metrics[\"ResNet50\"] = acc\n",
    "\n",
    "print(f\"ResNet50 entrenado correctamente - Loss: {loss:.4f}, Accuracy: {acc:.4f}\")"
   ],
   "id": "5cadd60bfdb1fd10",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evaluación y comparación",
   "id": "b534776dcecda277"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Gráfica de precisión",
   "id": "97a45733ee84c623"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# # Gráfica de comparación de precisión\n",
    "# plt.figure(figsize=(12, 6))\n",
    "#\n",
    "# # Agregar marcadores en los puntos de cada época\n",
    "# for model_name, history in history_dict.items():\n",
    "#     epochs = range(1, len(history.history[\"val_accuracy\"]) + 1)\n",
    "#     plt.plot(epochs, history.history[\"val_accuracy\"], marker='o', linestyle='-', label=f\"{model_name}\")\n",
    "#\n",
    "# plt.title(\"Comparación de precisión en validación\")\n",
    "# plt.xlabel(\"Epochs\")\n",
    "# plt.ylabel(\"Precisión\")\n",
    "# plt.xticks(epochs)\n",
    "# plt.legend()\n",
    "# plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# Obtener las épocas\n",
    "epochs = range(1, len(next(iter(history_dict.values())).history[\"accuracy\"]) + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Graficar solo la precisión en validación para comparación general\n",
    "for model_name, history in history_dict.items():\n",
    "    plt.plot(epochs, history.history[\"val_accuracy\"], marker='o', linestyle='-', label=f\"{model_name} - Validación\")\n",
    "\n",
    "# Configuración de la gráfica\n",
    "plt.xlabel(\"Épocas\")\n",
    "plt.ylabel(\"Precisión en Validación\")\n",
    "plt.title(\"Comparación de Precisión en Validación por Modelo\")\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "# Mostrar la gráfica\n",
    "plt.show()\n"
   ],
   "id": "bd6216b14db88553",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Curvas de aprendizaje",
   "id": "d09cacd8246b4668"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Graficar la curva de aprendizaje para cada modelo\n",
    "for model_name, history in history_dict.items():\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    # Graficar precisión en entrenamiento y validación\n",
    "    epochs = range(1, len(history.history[\"accuracy\"]) + 1)\n",
    "    plt.plot(epochs, history.history[\"accuracy\"], marker='o', linestyle='-', label=\"Entrenamiento\")\n",
    "    plt.plot(epochs, history.history[\"val_accuracy\"], marker='s', linestyle='-', label=\"Validación\")\n",
    "\n",
    "    # Configuración de la gráfica\n",
    "    plt.xlabel(\"Épocas\")\n",
    "    plt.ylabel(\"Precisión\")\n",
    "    plt.title(f\"Curva de Aprendizaje - {model_name}\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "    # Mostrar la gráfica\n",
    "    plt.show()"
   ],
   "id": "625a41d4054a9c1f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Reportes de clasificación",
   "id": "6838967a47f9a1c4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Evaluación y reporte de clasificación\n",
    "for model_name, model in {\n",
    "    \"CNN Simple\": cnn_simple,\n",
    "    \"CNN Profunda\": cnn_deep,\n",
    "    \"VGG16\": vgg16_model,\n",
    "    \"ResNet50\": resnet50_model\n",
    "}.items():\n",
    "    # Obtener las etiquetas reales (y_true) del dataset de prueba\n",
    "    y_true = np.concatenate([y.numpy() for _, y in test_dataset], axis=0)\n",
    "\n",
    "    # Obtener las predicciones del modelo sobre el dataset de prueba\n",
    "    y_pred = np.concatenate([model.predict(x, verbose=0) for x, _ in test_dataset], axis=0)\n",
    "\n",
    "    # Convertir las probabilidades en etiquetas binarias (0 = gato, 1 = perro)\n",
    "    y_pred = (y_pred > 0.5).astype(int)\n",
    "\n",
    "    # Mostrar el informe de clasificación para el modelo actual\n",
    "    print(f\"\\nClassification Report - {model_name}:\\n\")\n",
    "    print(classification_report(y_true, y_pred))"
   ],
   "id": "dad5a8785bb4ea63",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Matrices de confusión",
   "id": "431511e31a5b544d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_confusion_matrix(model, model_name, test_dataset):\n",
    "    # Obtener las etiquetas reales y las predicciones\n",
    "    y_true = np.concatenate([y.numpy() for _, y in test_dataset], axis=0)\n",
    "    y_pred = np.concatenate([model.predict(x, verbose=0) for x, _ in test_dataset], axis=0)\n",
    "    y_pred = (y_pred > 0.5).astype(int)\n",
    "\n",
    "    # Calcular la matriz de confusión\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    # Graficar la matriz de confusión\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Gato\", \"Perro\"], yticklabels=[\"Gato\", \"Perro\"])\n",
    "    plt.xlabel(\"Predicción\")\n",
    "    plt.ylabel(\"Etiqueta Real\")\n",
    "    plt.title(f\"Matriz de Confusión - {model_name}\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Dibujar la matriz de confusión para cada modelo\n",
    "for model_name, model in {\"CNN Simple\": cnn_simple, \"CNN Profunda\": cnn_deep, \"VGG16\": vgg16_model,\n",
    "                          \"ResNet50\": resnet50_model}.items():\n",
    "    print(f\"\\nMatriz de Confusión - {model_name}\")\n",
    "    plot_confusion_matrix(model, model_name, test_dataset)"
   ],
   "id": "6c54f67ced22549a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "\n",
    "Análisis por modelo (5 Epochs)\n",
    "\n",
    "\t1.\tCNN Simple\n",
    "\t•\tPrecisión en gatos: 2566/2766 ≈ 92.76%\n",
    "\t•\tPrecisión en perros: 1929/2750 ≈ 70.15%\n",
    "\n",
    "\t2.\tCNN Profunda (Con dropout)\n",
    "\t•\tPrecisión en gatos: 2466/2766 ≈ 89.13%\n",
    "\t•\tPrecisión en perros: 1991/2750 ≈ 72.4%\n",
    "\n",
    "\t3.\tVGG16 (Con dropout)\n",
    "\t•\tPrecisión en gatos: 2604/2766 ≈ 94.13%\n",
    "\t•\tPrecisión en perros: 2494/2750 ≈ 90.67%\n",
    "\n",
    "\t4.\tResNet50 (Con dropout)\n",
    "\t•\tPrecisión en gatos: 2278/2766 ≈ 82.37%\n",
    "\t•\tPrecisión en perros: 1490/2750 ≈ 54.18%\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Análisis por modelo (5 Epochs, sin Dropout)\n",
    "\n",
    "\t1.\tCNN Simple\n",
    "\t•\tPrecisión en gatos: 1991/3538 ≈ 56.29%\n",
    "\t•\tPrecisión en perros: 3323/3526 ≈ 94.24%\n",
    "\n",
    "\t2.\tCNN Profunda\n",
    "\t•\tPrecisión en gatos: 2895/3538 ≈ 81.85%\n",
    "\t•\tPrecisión en perros: 775/3526 ≈ 21.99%\n",
    "\n",
    "\t3.\tVGG16\n",
    "\t•\tPrecisión en gatos: 3318/3538 ≈ 93.78%\n",
    "\t•\tPrecisión en perros: 3303/3526 ≈ 93.68%\n",
    "\n",
    "\t4.\tResNet50\n",
    "\t•\tPrecisión en gatos: 3367/3538 ≈ 95.17%\n",
    "\t•\tPrecisión en perros: 1241/3526 ≈ 35.20%\n",
    "\n",
    "\"\"\""
   ],
   "id": "e6c7b6d788931860",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
